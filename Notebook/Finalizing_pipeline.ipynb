{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebb3ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load saved model and preprocessing artifacts once at module start\n",
    "model = joblib.load(r\"C:\\My stuff\\Coding\\ML project\\KiranveerSingh_projectfinal\\Models\\XGBoost.pkl\")\n",
    "scaler = joblib.load(r\"C:\\My stuff\\Coding\\ML project\\KiranveerSingh_projectfinal\\Models\\scaler.pkl\")\n",
    "categorical_columns = joblib.load(r\"C:\\My stuff\\Coding\\ML project\\KiranveerSingh_projectfinal\\Models\\X_train_cat_enc_columns.pkl\") \n",
    "# Feature engineering helper\n",
    "def add_features(df):\n",
    "    # Copy logic from your training phase\n",
    "    # --- Moving Averages ---\n",
    "    for window in [5, 10, 20]:\n",
    "        df[f\"SMA_{window}\"] = df.groupby(\"Symbol\")[\"Close\"].transform(lambda x: x.rolling(window).mean())\n",
    "\n",
    "    # --- Daily Returns ---\n",
    "    df['Return_1D'] = df.groupby('Symbol')['Close'].pct_change()\n",
    "\n",
    "    # --- Rolling Volatility ---\n",
    "    df['Volatility_10'] = df.groupby('Symbol')['Return_1D'].transform(lambda x: x.rolling(10).std())\n",
    "\n",
    "    # --- Price Ratios ---\n",
    "    df['High_Low_Ratio'] = df['High'] / df['Low']\n",
    "    df['Open_Close_Ratio'] = df['Open'] / df['Close']\n",
    "\n",
    "    # --- Volume Features ---\n",
    "    df['Volume_SMA_10'] = df.groupby('Symbol')['Volume'].transform(lambda x: x.rolling(10).mean())\n",
    "    df['Volume_Ratio'] = df['Volume'] / df['Volume_SMA_10']\n",
    "\n",
    "    # --- Lagged Features (prices and volume) ---\n",
    "    for lag in [1, 2, 3]:\n",
    "        df[f'Close_Lag_{lag}'] = df.groupby('Symbol')['Close'].shift(lag)\n",
    "        df[f'Volume_Lag_{lag}'] = df.groupby('Symbol')['Volume'].shift(lag)\n",
    "\n",
    "    # --- RSI Calculation (14-day window) ---\n",
    "    def calc_rsi(series, period=14):\n",
    "        delta = series.diff()\n",
    "        up = delta.clip(lower=0)\n",
    "        down = -1 * delta.clip(upper=0)\n",
    "        ema_up = up.ewm(com=period-1, adjust=False).mean()\n",
    "        ema_down = down.ewm(com=period-1, adjust=False).mean()\n",
    "        rs = ema_up / ema_down\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        return rsi\n",
    "\n",
    "    df['RSI_14'] = df.groupby(\"Symbol\")[\"Close\"].transform(lambda x: calc_rsi(x, 14))\n",
    "    # --- Remove rows with any missing values (due to rolling/lags) ---\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# The main pipeline function\n",
    "def predict_pipeline(input_df):\n",
    "    df = input_df.copy()\n",
    "    df = add_features(df)\n",
    "\n",
    "    # Select features as during training\n",
    "    exclude_cols = ['Date', 'Symbol', 'Will_Grow']\n",
    "    all_features = [col for col in df.columns if col not in exclude_cols]\n",
    "    numeric_features = df[all_features].select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_features = list(set(all_features) - set(numeric_features))\n",
    "\n",
    "    # Process categories as in training\n",
    "    X_num = df[numeric_features]\n",
    "    X_cat = df[categorical_features]\n",
    "    X_cat_enc = pd.get_dummies(X_cat, drop_first=True)\n",
    "    # Align dummies\n",
    "    X_cat_enc = X_cat_enc.reindex(columns=categorical_columns, fill_value=0)\n",
    "\n",
    "    # Combine\n",
    "    X = pd.concat([X_num.reset_index(drop=True), X_cat_enc.reset_index(drop=True)], axis=1)\n",
    "    # Reorder or rename columns to match the scaler/model\n",
    "    if hasattr(scaler, 'feature_names_in_'):\n",
    "        X = X.reindex(columns=scaler.feature_names_in_)\n",
    "    # Scale numerics\n",
    "    X[numeric_features] = scaler.transform(X[numeric_features])\n",
    "    # Predict\n",
    "    pred = model.predict(X)\n",
    "    prob = model.predict_proba(X)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    # Map prediction to class labels\n",
    "    direction = [\"Fall\" if p == 0 else \"Grow\" for p in pred]\n",
    "\n",
    "    # Build result DataFrame\n",
    "    res_df = df.copy()\n",
    "    res_df[\"Prediction\"] = direction\n",
    "    if prob is not None:\n",
    "        res_df[\"Probability\"] = prob\n",
    "    return res_df\n",
    "\n",
    "# Example usage:\n",
    "# new_raw_input = pd.read_csv(\"your_new_data.csv\")\n",
    "# prediction_df = predict_pipeline(new_raw_input)\n",
    "# print(prediction_df[[\"Date\", \"Symbol\", \"Prediction\", \"Probability\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ba6df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
